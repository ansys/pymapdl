# This action starts a MAPDL instance in a Docker container and runs the PyMAPDL test suite against it
name: |
  Test PyMAPDL with remote MAPDL instances

on:
  workflow_call:

    inputs:
      mapdl-version:
        description: |
          MAPDL version to test.
        required: true
        type: string

      file-name:
        description: |
          Name of the file to save the logs.
        required: true
        type: string

      upload-logs:
        description: |
          If true, logs will be uploaded encrypted. Set to false to disable log upload (for security).
        required: false
        type: boolean
        default: false

      python-version:
        description: |
          Python version to use.
        required: false
        type: string
        default: "3.12"

    secrets:
      username:
        description: |
          Username for the GitHub container registry.
        required: true

      token:
        description: |
          Token for GitHub.
        required: true

      license-server:
        description: |
          License server for ANSYS MAPDL
        required: true

      codecov-token:
        description: |
          Token for Codecov.
        required: true

      log-encryption-key:
        description: |
          Encryption key for sensitive log files.
        required: false

# zizmor: ignore[concurrency-limits]
# Concurrency is controlled by the parent workflow (ci.yml)

permissions: {}

jobs:
  test-remote:
    name: Test PyMAPDL with remote MAPDL instances
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Needed to read repository contents for tests
      packages: read  # Needed to pull Docker images from GitHub packages
    env:
      ON_CI: True
      ON_LOCAL: FALSE
      ON_UBUNTU: FALSE
      PYANSYS_OFF_SCREEN: True
      PYMAPDL_DEBUG_TESTING: True
      PYMAPDL_START_INSTANCE: FALSE
      PYMAPDL_PORT: 21000  # default won't work on GitHub runners
      PYMAPDL_PORT2: 21001  # for the pool testing and default won't work on GitHub runners
      PYMAPDL_DB_PORT: 21002  # default won't work on GitHub runners
      PYMAPDL_DB_PORT2: 21003  # default won't work on GitHub runners
      DPF_DOCKER_IMAGE: ghcr.io/ansys/mapdl:v25.2-rocky-dpf-standalone
      DPF_PORT: 21014
      DPF_PORT_INTERNAL: 50055 # Internal port for DPF server
      DPF_PORT2: 21015
      DPF_START_SERVER: False
      DPF_IP: '0.0.0.0'
      HAS_DPF: True
      TEST_DPF_BACKEND: false
      PYTEST_ARGUMENTS: '--ignore_image_cache'
      MAPDL_PACKAGE: ghcr.io/ansys/mapdl
      PYMAPDL_GRPC_TRANSPORT: 'insecure'
      DPF_DEFAULT_GRPC_MODE: 'insecure'

    steps:
      - name: "Freeing some space and show space consumption (pre-test)"
        shell: bash
        run: |
          echo "Deleting CodeQL..."
          rm -rf /__t/CodeQL || echo "CodeQL not found"

          echo "Disk space:"
          df -h

      - name: "Install Git and checkout project"
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd #v6.0.2
        with:
          persist-credentials: false

      - name: "Login in Github container registry"
        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 #v3.7.0
        with:
          registry: ghcr.io
          username: ${{ secrets.username }}
          password: ${{ secrets.token }}

      - name: "Getting SMP/DMP mode"
        id: distributed_mode
        shell: bash
        env:
          image: ${{ inputs.mapdl-version }}
        run: |
          export distributed_mode="smp"
          if [[ $image == *".1."* ]]; then
            export distributed_mode="dmp";
          fi
          echo "Distributed mode: $distributed_mode"
          echo "distributed_mode=$(echo $distributed_mode)" >> $GITHUB_OUTPUT

      - name: "Get if running on Ubuntu"
        id: ubuntu_check
        shell: bash
        env:
          MAPDL_VERSION: ${{ inputs.mapdl-version }}
        run: |
          export ON_SAME_CONTAINER=false

          if [[ "${MAPDL_VERSION}" == *"ubuntu"* ]];
            then export ON_UBUNTU=true; export TAG_UBUNTU="ubuntu";
            else export ON_UBUNTU=false; export TAG_UBUNTU="centos";
          fi

          if [[ "${MAPDL_VERSION}" == *"cicd"* ]]; then
            echo "CICD MAPDL version detected, testing DPF backend for results module.";
            echo "TEST_DPF_BACKEND=true" >> $GITHUB_ENV;

            echo "It should be run on the same container as MAPDL";
            export ON_SAME_CONTAINER=true;
          else
            echo "TEST_DPF_BACKEND=false" >> $GITHUB_ENV;
          fi

          if [[ "${MAPDL_VERSION}" == *"24.2"* ]]; then
            echo "MAPDL 24.2 detected, skipping DPF backend tests for results module.";
            echo "TEST_DPF_BACKEND=false" >> $GITHUB_ENV;
          fi

          echo "ON_UBUNTU: $ON_UBUNTU"
          echo "TAG_UBUNTU: $TAG_UBUNTU"
          echo "ON_SAME_CONTAINER: $ON_SAME_CONTAINER"

          echo "ON_UBUNTU=$(echo $ON_UBUNTU)" >> $GITHUB_OUTPUT
          echo "TAG_UBUNTU=$(echo $TAG_UBUNTU)" >> $GITHUB_OUTPUT
          echo "ON_SAME_CONTAINER=$(echo $ON_SAME_CONTAINER)" >> $GITHUB_OUTPUT

      - name: "Launch first MAPDL instance using action"
        id: mapdl_0
        uses: ./.github/actions/launch-mapdl-docker
        with:
          mapdl-image: ${{ env.MAPDL_PACKAGE }}:${{ inputs.mapdl-version }}
          instance-name: 'MAPDL_0'
          license-server: ${{ secrets.license-server }}
          pymapdl-port: ${{ env.PYMAPDL_PORT }}
          pymapdl-db-port: ${{ env.PYMAPDL_DB_PORT }}
          dpf-port: ${{ env.DPF_PORT }}
          enable-dpf-server: 'true'
          distributed-mode: ${{ steps.distributed_mode.outputs.distributed_mode }}
          wait: 'false'

      - name: "Launch second MAPDL instance for pool testing using action"
        id: mapdl_1
        uses: ./.github/actions/launch-mapdl-docker
        with:
          mapdl-image: ${{ env.MAPDL_PACKAGE }}:${{ inputs.mapdl-version }}
          instance-name: 'MAPDL_1'
          license-server: ${{ secrets.license-server }}
          pymapdl-port: ${{ env.PYMAPDL_PORT2 }}
          pymapdl-db-port: ${{ env.PYMAPDL_DB_PORT2 }}
          dpf-port: ${{ env.DPF_PORT2 }}
          enable-dpf-server: 'false'
          distributed-mode: ${{ steps.distributed_mode.outputs.distributed_mode }}

      - name: "Start DPF server on a separate container"
        shell: bash
        if: ${{ steps.ubuntu_check.outputs.ON_SAME_CONTAINER == 'false' }}
        env:
          ANSYS_DPF_ACCEPT_LA: Y
        run: |
          docker pull $DPF_DOCKER_IMAGE && docker run -d --name dpfserver --env ANSYS_DPF_ACCEPT_LA=Y -p ${DPF_PORT}:50052 $DPF_DOCKER_IMAGE && echo "DPF Server active on port ${DPF_PORT}." > log_dpf.log &

      - name: "Getting files change filters"
        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 #v3.0.2
        id: changes
        with:
          filters: |
            workflows:
              - '.github/workflows/**'

      - name: "Setup Python with cache"
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 #v6.2.0
        if:  steps.changes.outputs.workflows != 'true'
        with:
          cache: 'pip'
          python-version: ${{ inputs.python-version }}

      - name: "Setup Python without cache"
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 #v6.2.0
        if: steps.changes.outputs.workflows == 'true'
        with:
          python-version: ${{ inputs.python-version }}

      - name: "Install os packages"
        shell: bash
        run: |
          sudo apt update
          sudo apt install libgl1 libglx-mesa0 xvfb graphviz

      - name: "Test virtual framebuffer"
        shell: bash
        run: |
          ls -laR .
          pip install -r .ci/requirements_test_xvfb.txt
          xvfb-run python .ci/display_test.py

      - name: Install ansys-mapdl-core
        shell: bash
        run: |
          python -m pip install build
          python -m build
          python -m pip install dist/*.whl
          xvfb-run python -c "from ansys.mapdl import core as pymapdl; print(pymapdl.Report())"

      - name: "Unit testing requirements installation"
        shell: bash
        run: |
          python -m pip install .[tests]

      - name: "Unit testing"
        env:
          DISTRIBUTED_MODE: ${{ steps.distributed_mode.outputs.distributed_mode }}
          ON_UBUNTU: ${{ steps.ubuntu_check.outputs.ON_UBUNTU }}
          file_name: "${{ inputs.file-name }}"
          MAPDL_VERSION: "${{ inputs.mapdl-version }}"
          PYTEST_ARGUMENTS: "${{ env.PYTEST_ARGUMENTS }}"
        shell: bash
        run: |
          echo "ON_UBUNTU: $ON_UBUNTU"
          xvfb-run pytest \
            ${PYTEST_ARGUMENTS} \
            --report-log=$file_name.jsonl \
            --cov-report=xml:$file_name.xml

      - name: "Print amount of restarts"
        if: always()
        run: |
          N_RESTART=$(docker inspect --format '{{ .RestartCount }}'  MAPDL_0)
          echo "Number of restarts in the MAPDL_0 container: $N_RESTART"
          N_RESTART=$(docker inspect --format '{{ .RestartCount }}'  MAPDL_1)
          echo "Number of restarts in the MAPDL_1 container: $N_RESTART"

      - name: "Upload pytest reports to GitHub"
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f #v6.0.0
        with:
          name: "reports-${{ inputs.file-name }}"
          path: ./${{ inputs.file-name }}.jsonl

      - uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de #v5.5.2
        name: "Upload coverage to Codecov"
        with:
          token: ${{ secrets.codecov-token }} # required
          name: "${{ inputs.file-name }}.xml"
          flags: remote-${{ steps.ubuntu_check.outputs.TAG_UBUNTU }}-${{ inputs.mapdl-version }}-${{ steps.distributed_mode.outputs.distributed_mode }}

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f #v6.0.0
        with:
          name: "${{ inputs.file-name }}.xml"
          path: "./${{ inputs.file-name }}.xml"

      - name: "Check package"
        shell: bash
        run: |
          pip install twine
          twine check dist/*

      - name: "Upload wheel and binaries"
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f #v6.0.0
        with:
          name: PyMAPDL-packages-${{ inputs.mapdl-version }}
          path: dist/
          retention-days: 7

      - name: "Collect logs"
        if: always()
        env:
          MAPDL_VERSION: ${{ inputs.mapdl-version }}
          MAPDL_INSTANCE: MAPDL_0
          LOG_NAMES: logs-${{ inputs.file-name }}
        shell: bash
        run: |
          .ci/collect_mapdl_logs_remote.sh

      - name: "Encrypt and upload logs to GitHub"
        if: always() && inputs.upload-logs == true
        env:
          ENCRYPTION_KEY: ${{ secrets.log-encryption-key }}
          FILE_NAME: ${{ inputs.file-name }}
        shell: bash
        run: |
          # Check if logs exist
          if [ -f "./logs-${FILE_NAME}.tgz" ]; then
            echo "Encrypting logs..."

            # Encrypt using OpenSSL
            openssl enc -aes-256-cbc -salt -pbkdf2 \
              -in ./logs-${FILE_NAME}.tgz \
              -out ./logs-${FILE_NAME}.tgz.enc \
              -pass env:ENCRYPTION_KEY

            echo "Logs encrypted successfully"
            echo "To decrypt locally, use:"
            echo "openssl enc -aes-256-cbc -d -pbkdf2 -in logs-${FILE_NAME}.tgz.enc -out logs-${FILE_NAME}.tgz -pass pass:YOUR_KEY"
          else
            echo "No log file found to encrypt"
          fi

      - name: "Upload encrypted logs to GitHub"
        if: always() && inputs.upload-logs == true
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f #v6.0.0
        with:
          name: logs-${{ inputs.file-name }}-encrypted
          path: ./logs-${{ inputs.file-name }}.tgz.enc
          retention-days: 3

      - name: "Show space consumption (post-test)"
        if: always()
        shell: bash
        run: |
          echo "Disk space:"
          df -h
